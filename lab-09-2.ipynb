{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 09-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 steps of using TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. From TF graph, decide which tensors you want to log\n",
    "    ```python\n",
    "    w2_hist = tf.summary.histogram(\"weights2\", W2) # multi-dimensional tensors\n",
    "    cost_summ = tf.summary.scalar(\"cost\", cost)\n",
    "    ```\n",
    "\n",
    "2. Merge all summaries\n",
    "    ```python\n",
    "    summary = tf.summary.merge_all()\n",
    "    ```\n",
    "\n",
    "3. Create writer and add graph\n",
    "    ```python\n",
    "    writer = tf.summary.FileWriter('./logs')\n",
    "    writer.add_graph(sess.graph)\n",
    "    ```\n",
    "\n",
    "4. Run summary merge and add summary\n",
    "    ```python\n",
    "    s, _ = sess.run([summary, optimizer], feed_dict=feed_dict)\n",
    "    writer.add_summary(s, global_step=global_step)\n",
    "    ```\n",
    "\n",
    "5. Launch TensorBoard\n",
    "    ```python\n",
    "    tensorboard --logdir=./logs\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add scope for better graph hierarchy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "with tf.name_scope('layer1') as scope:\n",
    "    ...\n",
    "    \n",
    "with tf.name_scope('layer2') as scope:\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```tf.summary.FileWriter```에 ```logs/xor_logs, logs/xor_logs_r0_01```과 같이 하위 디렉토리 이름을 다르게 해서 저장한 후, ```tensorboard --logdir=./logs```를 이용해 보면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - TensorBoard for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinhyuk/tensorflow/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0001 cost = 1.776198500\n",
      "Epoch: 0002 cost = 1.103110467\n",
      "Epoch: 0003 cost = 0.856227727\n",
      "Epoch: 0004 cost = 0.719479916\n",
      "Epoch: 0005 cost = 0.630894968\n",
      "Epoch: 0006 cost = 0.569035370\n",
      "Epoch: 0007 cost = 0.523353374\n",
      "Epoch: 0008 cost = 0.488216158\n",
      "Epoch: 0009 cost = 0.459423770\n",
      "Epoch: 0010 cost = 0.435303340\n",
      "Epoch: 0011 cost = 0.414649513\n",
      "Epoch: 0012 cost = 0.397563543\n",
      "Epoch: 0013 cost = 0.381769914\n",
      "Epoch: 0014 cost = 0.368472253\n",
      "Epoch: 0015 cost = 0.356472811\n",
      "Accuracy:  0.8867\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([784, 40]), name='weight1')\n",
    "b1 = tf.Variable(tf.random_normal([40]), name='bias1')\n",
    "layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([40, 40]), name='weight2')\n",
    "b2 = tf.Variable(tf.random_normal([40]), name='bias2')\n",
    "layer2 = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([40, 40]), name='weight3')\n",
    "b3 = tf.Variable(tf.random_normal([40]), name='bias3')\n",
    "layer3 = tf.sigmoid(tf.matmul(layer2, W3) + b3)\n",
    "\n",
    "W4 = tf.Variable(tf.random_normal([40, 40]), name='weight4')\n",
    "b4 = tf.Variable(tf.random_normal([40]), name='bias4')\n",
    "layer4 = tf.sigmoid(tf.matmul(layer3, W4) + b4)\n",
    "\n",
    "W5 = tf.Variable(tf.random_normal([40, 10]), name='weight5')\n",
    "b5 = tf.Variable(tf.random_normal([10]), name='bias5')\n",
    "hypothesis = tf.nn.softmax(tf.matmul(layer4, W5) + b5)\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "prediction = tf.argmax(hypothesis, axis=1)\n",
    "is_correct = tf.equal(prediction, tf.argmax(Y, axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "epochs = 15\n",
    "batch_size = 100\n",
    "num_iteartions = int(mnist.train.images.shape[0] / batch_size)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "tf.summary.histogram('weight1', W1)\n",
    "tf.summary.histogram('weight2', W2)\n",
    "tf.summary.histogram('weight3', W3)\n",
    "tf.summary.histogram('weight4', W4)\n",
    "tf.summary.histogram('weight5', W5)\n",
    "tf.summary.scalar('cost', cost)\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "summary = tf.summary.merge_all()\n",
    "\n",
    "writer = tf.summary.FileWriter('./logs')\n",
    "writer.add_graph(sess.graph)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_cost = 0\n",
    "\n",
    "    for i in range(num_iteartions):\n",
    "        batch_x_data, batch_y_data = mnist.train.next_batch(batch_size)\n",
    "\n",
    "        s, cost_val, _ = sess.run([summary, cost, train], feed_dict={X: batch_x_data, Y: batch_y_data})\n",
    "\n",
    "        total_cost += cost_val\n",
    "        writer.add_summary(s, global_step=(epoch * num_iteartions + i))\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(total_cost / num_iteartions))\n",
    "\n",
    "acc_val = sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels})\n",
    "print(\"Accuracy: \", acc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
